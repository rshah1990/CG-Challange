{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "%matplotlib inline\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport os\nfrom sklearn.preprocessing import MinMaxScaler",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0a76cb9c18b4d38c98b4a14e35744bdc382fca38"
      },
      "cell_type": "code",
      "source": "# from tf.keras.models import Sequential  # This does not work!\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Input, Dense, GRU, Embedding\nfrom tensorflow.python.keras.optimizers import RMSprop\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "headcount = pd.read_excel('../input/Demandv1.1.xlsx',sheet_name='Headcount')\n# billable data shows actual demand of past years\nheadcount = headcount[headcount.Status == 'Billable']",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7de5e7287f2d0c9d64c6f8f7ad4a5e96023c7b20"
      },
      "cell_type": "code",
      "source": "# converting Technologies into one hot encoding\nfrom re import split\ncleaned = headcount.set_index('Employee Code').SkillList.str.split(r',\\s*(?![^()]*\\))', expand=True).stack()\none_hot_coded_df = pd.get_dummies(cleaned).groupby(level=0).sum()\none_hot_coded_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ff5fb730442083b7d918d9a9466b9ed94ae122f4"
      },
      "cell_type": "code",
      "source": "# making index as Employee code for main data frame\nhead_df = pd.read_excel('../input/Demandv1.1.xlsx',sheet_name='Headcount',index_col='Employee Code')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7b4a2cf846b4046405d7a52ecdc5d2d945c6cfb6"
      },
      "cell_type": "code",
      "source": "# merging to daat frame\nmerged_df = pd.merge(head_df,one_hot_coded_df,left_index=True,right_index=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8d0e47c942b5bf746fed927c5840688db70d2d6d"
      },
      "cell_type": "code",
      "source": "# removing index and unwanted columns\nremoved_index = merged_df.reset_index(drop=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3e07bf1661fc2c1989973368f9dcf47678621f37"
      },
      "cell_type": "code",
      "source": "final_df = removed_index.drop(['Region','  Last Name','Status','Market Unit','SkillList'],axis=1).set_index('Local Date of Joining')\nfinal_df['year'] = final_df.index.year\nfinal_df['month']=final_df.index.month\ngrouped_df = final_df.reset_index(drop=True).groupby(['year','month','Location','Designation']).sum()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "334d497709d0a7432575701bc5cd08d5166e315e"
      },
      "cell_type": "code",
      "source": "def predict_loc_tech(location,technology,desgination):\n    if location is None and desgination is None:\n        location_df = grouped_df\n    elif location is None and desgination:\n        location_df = grouped_df[(grouped_df.index.get_level_values('Designation') == desgination)]\n    elif desgination is None and location:\n        location_df = grouped_df[(grouped_df.index.get_level_values('Location') == location)]\n    elif location and desgination:\n        location_df = grouped_df[(grouped_df.index.get_level_values('Location') == location) & (grouped_df.index.get_level_values('Designation') == desgination)]\n    location_df['day'] = 1\n    location_df = location_df.reset_index()\n    location_df = location_df[location_df.year >= 2010]\n    location_df['Date']=pd.to_datetime(location_df[['year','month','day']])\n    loc_tech_df = location_df.set_index('Date').resample('M').sum()[[technology]]\n    return loc_tech_df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8b9f7b8f0866edcc03baf26631abb2da73807e98"
      },
      "cell_type": "code",
      "source": "find_df = predict_loc_tech(None,'Java',None) #4.891495\nfind_df = find_df.apply(np.log1p)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "02e193a28e414ca29f58af267856e6e9521ed221"
      },
      "cell_type": "code",
      "source": "find_df.sort_index(ascending=True,inplace=True)\nfind_df.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e427758e3ff263b332f86fcb12484d9717cd43e3"
      },
      "cell_type": "code",
      "source": "plt.figure(figsize=(15, 5));\nplt.plot(find_df, color='red', label='Java')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f459fcaf0dc5c0625198d16a11c788c5c5d30645"
      },
      "cell_type": "code",
      "source": "shift_months = 12\ntarget_names = 'Java'\ndf_targets = find_df[target_names].shift(-shift_months)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6bce9f53b98bb661e73e50c1aaa1c90f404456eb"
      },
      "cell_type": "code",
      "source": "test_df = find_df.tail(12)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0858728a5594def8f97224f0bbcfbce0eee9ca82"
      },
      "cell_type": "code",
      "source": "traning_df = find_df[:-12]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "686a6a5e80ccf9fc46de26229e675f1c00f8cd20"
      },
      "cell_type": "code",
      "source": "x_data = traning_df.values\nprint(x_data.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9423bf6c894d63ec23fcd22f84c40a79ed8411ea"
      },
      "cell_type": "code",
      "source": "y_data = df_targets.values[:-shift_months].reshape(88,1)\nprint(y_data.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "13044e88f215979389036d8257ea47f5a60c5ab9"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val = train_test_split(x_data,y_data,test_size = 0.1,shuffle=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d9c176ca2f041e3eaa5e3ed210e2b039c6b811c6"
      },
      "cell_type": "code",
      "source": "# Number of input features\nnum_x_signals = x_data.shape[1]\nnum_x_signals",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cd7121ac759b321bfc86f3dacf38fade0453ecf2"
      },
      "cell_type": "code",
      "source": "# number of target\nnum_y_signals = y_data.shape[1]\nnum_y_signals",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e6f3471c21ce4a82a2d05cf40e13aebf97eaf145"
      },
      "cell_type": "code",
      "source": "# scale Data\n# x_scalerx_scaler = MinMaxScaler()\n# x_train_scaled = x_scalerx_scaler.fit_transform(x_train)\nx_train_scaled =x_train\n# x_scaled_val = x_scalerx_scaler.fit_transform(x_val)\nx_scaled_val = x_val",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "05fbca5f9cd572984c2b1060767407d4b0325e8d"
      },
      "cell_type": "code",
      "source": "print(x_train_scaled.shape)\nprint(y_train.shape)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7d1bda1567979374719a9f8dd47be455d8b00fde"
      },
      "cell_type": "code",
      "source": "def batch_generator(batch_size, sequence_length):\n    \"\"\"\n    Generator function for creating random batches of training-data.\n    \"\"\"\n\n    # Infinite loop.\n    while True:\n        # Allocate a new array for the batch of input-signals.\n        x_shape = (batch_size, sequence_length, num_x_signals)\n        x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n\n        # Allocate a new array for the batch of output-signals.\n        y_shape = (batch_size, sequence_length, num_y_signals)\n        y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n\n        # Fill the batch with random sequences of data.\n        for i in range(batch_size):\n            # Get a random start-index.\n            # This points somewhere into the training-data.\n            idx = np.random.randint(len(x_train_scaled) - sequence_length)\n            \n            # Copy the sequences of data starting at this index.\n            x_batch[i] = x_train_scaled[idx:idx+sequence_length]\n            y_batch[i] = y_train[idx:idx+sequence_length]\n        \n        yield (x_batch, y_batch)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5e735278cef5bf26744024446a269cb554ce25c1"
      },
      "cell_type": "code",
      "source": "# batch size and sequence\nbatch_size = 15\nsequence_length= 12*1 # we will go four years data at a time",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a66c6149680a3039a85ba38b0ad1990583f6f7f4"
      },
      "cell_type": "code",
      "source": "generator = batch_generator(batch_size=batch_size,\n                            sequence_length=sequence_length)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "180f510c5b46d61db9cb13067815bbcece98bd72"
      },
      "cell_type": "code",
      "source": "x_batch, y_batch = next(generator)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9071d122b627382655eb2d8c55dc452e54f40b75"
      },
      "cell_type": "code",
      "source": "validation_data = (np.expand_dims(x_scaled_val, axis=0),\n                   np.expand_dims(y_val, axis=0))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e13260ec601246ee702d9966665a2d88812ffda"
      },
      "cell_type": "code",
      "source": "model = Sequential()\nmodel.add(GRU(units=256,\n              return_sequences=True,\n              input_shape=(None, num_x_signals,)))\nmodel.add(Dense(num_y_signals, activation='tanh'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "82fa784bd76b97294861b8c201b1249f5cfa45e4"
      },
      "cell_type": "code",
      "source": "optimizer = RMSprop(lr=1e-3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "323416dfe42017fc73bab183696ac0d72821ee9c"
      },
      "cell_type": "code",
      "source": "def loss_mse_warmup(y_true, y_pred):\n    \"\"\"\n    Calculate the Mean Squared Error between y_true and y_pred,\n    but ignore the beginning \"warmup\" part of the sequences.\n    \n    y_true is the desired output.\n    y_pred is the model's output.\n    \"\"\"\n\n\n    # Calculate the MSE loss for each value in these tensors.\n    # This outputs a 3-rank tensor of the same shape.\n    loss = tf.losses.mean_squared_error(labels=y_true,\n                                        predictions=y_pred)\n\n    # Keras may reduce this across the first axis (the batch)\n    # but the semantics are unclear, so to be sure we use\n    # the loss across the entire tensor, we reduce it to a\n    # single scalar with the mean function.\n    loss_mean = tf.reduce_mean(loss)\n\n    return loss_mean",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e36190fe51439021d5d8774f17362f6764a47ef6"
      },
      "cell_type": "code",
      "source": "model.compile(loss=loss_mse_warmup,\n              optimizer=optimizer)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "09d7aa18171a9b6c1ae7abe707252cb50123c234"
      },
      "cell_type": "code",
      "source": "model.summary()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b7d189e2c62e742141a205471b780ea66214db0e"
      },
      "cell_type": "code",
      "source": "# call back function\npath_checkpoint = '23_checkpoint.keras'\ncallback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n                                      monitor='val_loss',\n                                      verbose=1,\n                                      save_weights_only=True,\n                                      save_best_only=True)\ncallback_early_stopping  = EarlyStopping(monitor='val_loss',\n                                        patience=5, verbose=1)\ncallback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                                       factor=0.1,\n                                       min_lr=1e-4,\n                                       patience=2,\n                                       verbose=1)\ncallback_tensorboard = TensorBoard(log_dir='./23_logs/',\n                                   histogram_freq=0,\n                                   write_graph=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "452734d70d532befde1334775bdd24de9006ae3c"
      },
      "cell_type": "code",
      "source": "callbacks = [callback_early_stopping,\n             callback_checkpoint,\n             callback_tensorboard,\n             callback_reduce_lr]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dad63542bf71c4d872a388b77eaeca3dfd961c23"
      },
      "cell_type": "code",
      "source": "%%time\nmodel.fit_generator(generator=generator,\n                    epochs=50,\n                    steps_per_epoch=100,\n                    validation_data=validation_data,\n                    callbacks=callbacks)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0717b55d63e67e191570726181be7398f81eb7bc"
      },
      "cell_type": "code",
      "source": "result = model.evaluate(x=np.expand_dims(x_scaled_val, axis=0),\n                        y=np.expand_dims(y_val, axis=0))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ed76a57397eb976c3d7d65377282fb22d66ce69d"
      },
      "cell_type": "code",
      "source": "print(\"loss (test-set):\", result)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8f5264109b35db6a4e5b14bbbc49331e15012b89"
      },
      "cell_type": "code",
      "source": "def plot_comparison(start_idx, length=100, train=True):\n    \"\"\"\n    Plot the predicted and true output-signals.\n    \n    :param start_idx: Start-index for the time-series.\n    :param length: Sequence-length to process and plot.\n    :param train: Boolean whether to use training- or test-set.\n    \"\"\"\n    \n    if train:\n        # Use training-data.\n        x = x_train_scaled\n        y_true = y_train\n    else:\n        # Use test-data.\n        x = x_scaled_val\n        y_true = y_val\n    \n    # End-index for the sequences.\n    end_idx = start_idx + length\n    \n    # Select the sequences from the given start-index and\n    # of the given length.\n    x = x[start_idx:end_idx]\n    y_true = y_true[start_idx:end_idx]\n    \n    # Input-signals for the model.\n    x = np.expand_dims(x, axis=0)\n    print(x.shape)\n    # Use the model to predict the output-signals.\n    y_pred = model.predict(x)\n    print(y_pred)\n    \n    # The output of the model is between 0 and 1.\n    # Do an inverse map to get it back to the scale\n    # of the original data-set.\n    y_pred_rescaled = y_pred[0]\n    \n    \n    # For each output-signal.\n    for signal in range(len(target_names)):\n        # Get the output-signal predicted by the model.\n        signal_pred = y_pred_rescaled[:, signal]\n        print(signal_pred)\n        \n        # Get the true output-signal from the data-set.\n        signal_true = y_true[:, signal]\n        print(signal_true)\n\n        # Make the plotting-canvas bigger.\n        plt.figure(figsize=(15,5))\n        \n        # Plot and compare the two signals.\n        plt.plot(signal_true, label='true')\n        plt.plot(signal_pred, label='pred')\n        \n        # Plot grey box for warmup-period.\n        p = plt.axvspan(0, warmup_steps, facecolor='black', alpha=0.15)\n        \n        # Plot labels etc.\n        plt.ylabel(target_names[signal])\n        plt.legend()\n        plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4df477e33cb6cf6c84255f2159056f92896ca312"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}